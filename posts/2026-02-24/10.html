<!DOCTYPE html>
<html lang="zh-Hant">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>資安討論：香港銀行業 Deep Fake 視像詐騙急增 三個月損失逾億港元</title>
<style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; background: #f5f5f7; color: #1d1d1f; line-height: 1.7; padding: 20px 16px 40px; }
.wrap { max-width: 680px; margin: 0 auto; }
.badge { display: inline-block; background: #007aff; color: #fff; font-size: 12px; padding: 2px 10px; border-radius: 12px; margin: 0 4px 12px 0; }
h1 { font-size: 22px; line-height: 1.4; margin-bottom: 16px; }
h2 { font-size: 18px; margin: 28px 0 12px; color: #1d1d1f; }
p { font-size: 16px; margin-bottom: 16px; text-align: justify; }
.back { display: inline-block; margin-top: 32px; color: #007aff; text-decoration: none; font-size: 15px; }
.back:hover { text-decoration: underline; }
</style>
</head>
<body>
<div class="wrap">
<span class="badge">資訊安全</span><span class="badge">2026-02-24</span>
<h1>🔐 香港銀行業 Deep Fake 視像詐騙急增 三個月損失逾億港元</h1>

<h2>香港警方公佈最新詐騙數據</h2>
<p>香港警務處網絡安全及科技罪案調查科（CSTCB）今日公佈 2025 年第四季度至 2026 年第一季度的科技騙案統計數據，其中最令業界震驚的是 Deep Fake 視像詐騙案件的急速增長。在過去三個月內，本港銀行業共錄得 78 宗已確認的 Deep Fake 視像詐騙案件，涉及損失金額合計逾 1.07 億港元，平均每宗案件的損失金額高達 137 萬港元。警方指出，案件數量及金額均較上一個季度大幅上升超過 300%，顯示詐騙集團已能大規模、系統化地製作和應用高質素的 Deep Fake 視像。</p>

<h2>典型作案手法分析</h2>
<p>警方公開了多宗典型案例的作案手法，以協助企業提高警覺。最常見的模式是詐騙集團先通過社交媒體和公開渠道收集目標企業高管的視像資料，利用最新的 AI 換臉和聲音克隆技術製作高度逼真的深度偽造視像，再以視像通話的形式「假扮」企業 CEO 或財務總監，指示財務部門員工緊急進行大額跨境轉賬。部分案例中，詐騙集團更事先入侵目標高管的電郵帳戶，結合真實的企業內部通訊記錄，令整個詐騙場景更具說服力，即使受過相關培訓的員工也難以即時識破。</p>

<h2>連登資安版的熱烈討論</h2>
<p>消息傳出後，連登資安討論版立即掀起熱烈辯論，主要圍繞三個核心問題展開：企業應如何建立有效的 Deep Fake 識別機制、銀行在此類詐騙中應承擔多少賠償責任，以及現有的反詐法規是否已落後於技術發展。多位自稱在金融機構從事資訊安全的網民分享了業界實際採用的防禦措施，包括要求所有視像指示的財務操作必須附有額外的帶外（out-of-band）驗證，以及引入「活體檢測挑戰」（Liveness Challenge）要求視像通話對象完成特定隨機動作以排除預錄視像的可能性。</p>

<h2>技術防禦方案與業界應對</h2>
<p>面對 Deep Fake 詐騙的快速演進，香港金融管理局已向所有持牌銀行發出指引，要求在 2026 年底前部署 AI 驅動的 Deep Fake 視像偵測系統，並強化對高風險財務操作的多重認證機制。多家國際網絡安全公司已在本港推出針對 Deep Fake 視像的實時偵測服務，採用的技術包括面部微表情分析、視頻壓縮人工痕跡識別和光影物理一致性驗證等多種方法。然而，安全研究人員警告指出，隨著 Deep Fake 生成技術的持續進步，「道高一尺、魔高一丈」的攻防博弈將長期持續，技術防禦必須與人員培訓和流程管控相結合才能有效降低風險。</p>

<h2>立法與監管層面的回應</h2>
<p>Deep Fake 詐騙案件的急速增長亦引發了立法層面的關注。多名立法會議員向保安局提交質詢，要求當局說明現行法例在應對 AI 生成詐騙材料方面的充分性，並探討制訂專門針對 Deep Fake 詐騙的刑事條例的可行性。法律學者指出，現行《防止網絡及科技犯罪條例》的相關條文在制訂時未曾預見 AI 生成欺詐材料的情景，部分技術性條文存在灰色地帶，有必要進行修訂以確保相關犯罪行為能得到有效的法律規管。保安局局長表示當局正積極研究立法修訂方向，預計在年底前提出相關建議。</p>

<a href="/posts/2026-02-24.html" class="back">← 返回 2026-02-24 每日摘要</a>
</div>
</body>
</html>
